#!/usr/bin/env python3
"""
Generate AI insights using OpenRouter free models
Supports Arabic language with multiple free model fallbacks
"""

import json
import os
import sys
from datetime import datetime
import urllib.request
import urllib.error

# Free models from OpenRouter (no cost)
FREE_MODELS = [
    "qwen/qwen-2-7b-instruct:free",  # Best for Arabic
    "google/gemma-2-9b-it:free",
    "meta-llama/llama-3.2-3b-instruct:free",
    "microsoft/phi-3-mini-128k-instruct:free"
]

def call_openrouter(prompt, api_key, model=None):
    """Call OpenRouter API with free model"""
    if not api_key:
        print("âš ï¸ No OpenRouter API key provided")
        return None
    
    model = model or FREE_MODELS[0]
    print(f"ğŸ¤– Calling {model}...")
    
    url = "https://openrouter.ai/api/v1/chat/completions"
    
    data = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 2000
    }
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json',
        'HTTP-Referer': 'https://github.com/kaledh4/calc',
        'X-Title': 'Smart Finance Calculator'
    }
    
    try:
        req = urllib.request.Request(
            url,
            data=json.dumps(data).encode('utf-8'),
            headers=headers,
            method='POST'
        )
        
        with urllib.request.urlopen(req, timeout=30) as response:
            result = json.loads(response.read().decode())
            content = result['choices'][0]['message']['content']
            print(f"âœ… AI response received ({len(content)} chars)")
            return content
            
    except urllib.error.HTTPError as e:
        print(f"âŒ HTTP Error {e.code}: {e.reason}")
        return None
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None

def generate_insights():
    """Generate SMART & CONCISE AI insights"""
    api_key = os.getenv('OPENROUTER_API_KEY', '')
    
    # Load data
    try:
        with open('data/inflation.json', 'r', encoding='utf-8') as f: inflation = json.load(f)
    except: inflation = {'current': 2.5, 'change': 0.0}
    
    try:
        with open('data/news.json', 'r', encoding='utf-8') as f: 
            news = json.load(f)
            news_headlines = ' | '.join([n['title'] for n in news[:3]]) # Only top 3, concise
    except: news_headlines = "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø± Ù‡Ø§Ù…Ø©"
    
    # SMART PROMPT - DIRECT & AGGRESSIVE
    prompt = f"""
    Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø§Ù„ÙŠ Ø®Ø¨ÙŠØ± ÙˆÙ…Ø®ØªØµØ± Ø¬Ø¯Ø§Ù‹. Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø¹Ø¨Ø§Ø±Ø§Øª ØªØ±Ø­ÙŠØ¨ÙŠØ©.
    
    Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
    - Ø§Ù„ØªØ¶Ø®Ù…: {inflation['current']}%
    - Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {news_headlines}
    
    Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙˆØ±Ø§Ù‹):
    
    1. ğŸ“‰ **Ø­Ù‚ÙŠÙ‚Ø© Ø£Ù…ÙˆØ§Ù„Ùƒ:**
    Ø§Ø­Ø³Ø¨ Ø¨Ø¯Ù‚Ø©: ÙƒÙ… ÙŠØ®Ø³Ø± Ø±Ø§ØªØ¨ 10,000 Ø±ÙŠØ§Ù„ Ù…Ù† Ù‚ÙˆØªÙ‡ Ø§Ù„Ø´Ø±Ø§Ø¦ÙŠØ© Ø³Ù†ÙˆÙŠØ§Ù‹ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ø¯Ù„ØŸ (Ø£Ø¹Ø·Ù†ÙŠ Ø§Ù„Ø±Ù‚Ù… ÙÙ‚Ø·).
    
    2. ğŸ’¡ **Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ÙÙˆØ±ÙŠ:**
    Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ§Ù„ØªØ¶Ø®Ù…ØŒ Ø£Ø¹Ø·Ù†ÙŠ Ù†ØµÙŠØ­Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø© Ø¬Ø¯Ø§Ù‹ (Ø´Ø±Ø§Ø¡/Ø¨ÙŠØ¹/Ø³Ø¯Ø§Ø¯) Ø§Ù„ÙŠÙˆÙ…. Ù„Ø§ ØªÙ‚Ù„ "Ø±Ø§Ù‚Ø¨" Ø£Ùˆ "ÙˆÙØ±"ØŒ ÙƒÙ† Ù…Ø­Ø¯Ø¯Ø§Ù‹.
    
    3. ğŸ”® **Ù†Ø¸Ø±Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„:**
    ÙÙŠ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©: Ù‡Ù„ Ù†ØªØ¬Ù‡ Ù„Ø±ÙƒÙˆØ¯ Ø£Ù… Ø§Ù†ØªØ¹Ø§Ø´ØŸ ÙˆÙ„Ù…Ø§Ø°Ø§ (Ø¨ÙƒÙ„Ù…ØªÙŠÙ†)ØŸ
    
    4. ğŸ¦ **Ø­ÙƒÙ…Ø© Ø§Ù„Ù‚Ø±ÙˆØ¶:**
    Ù‡Ù„ Ø§Ù„ÙˆÙ‚Øª Ù…Ù†Ø§Ø³Ø¨ Ù„Ø£Ø®Ø° Ù‚Ø±Ø¶ Ø§Ù„ÙŠÙˆÙ…ØŸ (Ù†Ø¹Ù…/Ù„Ø§) ÙˆÙ„Ù…Ø§Ø°Ø§ Ø­Ø³Ø§Ø¨ÙŠØ§Ù‹ØŸ
    """

    # Try to get AI insights
    insights_text = None
    
    if api_key:
        # Use Gemini 2.0 Flash (Fast & Smart) or Llama 3.2 as fallback
        models = ["google/gemini-2.0-flash-exp:free", "meta-llama/llama-3.2-3b-instruct:free"]
        for model in models:
            insights_text = call_openrouter(prompt, api_key, model)
            if insights_text: break
    
    # Fallback if no API key or failure
    if not insights_text:
        loss = 10000 * (inflation['current'] / 100)
        insights_text = f"""
        1. ğŸ“‰ **Ø­Ù‚ÙŠÙ‚Ø© Ø£Ù…ÙˆØ§Ù„Ùƒ:** Ø±Ø§ØªØ¨ 10,000 ÙŠØ®Ø³Ø± {loss:.0f} Ø±ÙŠØ§Ù„ Ø³Ù†ÙˆÙŠØ§Ù‹ Ù…Ù† Ù‚ÙŠÙ…ØªÙ‡ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©.
        2. ğŸ’¡ **Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ÙÙˆØ±ÙŠ:** ÙØ¹Ù‘Ù„ Ù…ÙØªØ§Ø­ AI Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØµÙŠØ­Ø© Ø°ÙƒÙŠØ© Ù…Ø®ØµØµØ©.
        3. ğŸ”® **Ù†Ø¸Ø±Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„:** Ø§Ù„ØªØ¶Ø®Ù… {inflation['current']}% ÙŠØªØ·Ù„Ø¨ Ø­Ù…Ø§ÙŠØ© Ù…Ø¯Ø®Ø±Ø§ØªÙƒ Ø¨Ø£ØµÙˆÙ„ Ø­Ù‚ÙŠÙ‚ÙŠØ©.
        4. ğŸ¦ **Ø­ÙƒÙ…Ø© Ø§Ù„Ù‚Ø±ÙˆØ¶:** Ø§Ù„ÙØ§Ø¦Ø¯Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© = Ø§Ù„ÙØ§Ø¦Ø¯Ø© Ø§Ù„Ø§Ø³Ù…ÙŠØ© - {inflation['current']}%. Ø§Ø­Ø³Ø¨Ù‡Ø§ Ø¬ÙŠØ¯Ø§Ù‹.
        """

    # Create insights object
    insights = {
        'summary': insights_text,
        'timestamp': datetime.utcnow().isoformat(),
        'model': 'Smart-AI',
        'language': 'ar'
    }
    
    # Save insights
    os.makedirs('data', exist_ok=True)
    with open('data/insights.json', 'w', encoding='utf-8') as f:
        json.dump(insights, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Smart Insights Generated")
    return insights

if __name__ == '__main__':
    generate_insights()
